# ğŸ“ MBO-DeBERTa Review Classifier

A Machine Learning/NLP pipeline to automatically detect low-quality reviews (Advertisements, Irrelevant Content, Rants Without Visit) and classify Valid Reviews, optimized with Monarch Butterfly Optimizer (MBO) on top of DeBERTa.
Outputs confidence percentages per class, with a Streamlit demo app for real-time testing.

---

## ğŸš€ Features

â€¢ DeBERTa Transformer Backbone for powerful text encoding  
â€¢ MBO (Monarch Butterfly Optimization) for hyperparameter tuning  
â€¢ Softmax Confidence Scores for each predicted category  
â€¢ Hybrid Pipeline: rule-based + ML classification  
â€¢ Explainability (via SHAP) to highlight key words influencing predictions  
â€¢ Streamlit UI to demo review classification live

---

## ğŸ“‚ Project Structure

```
mbo-deberta-project/
â”œâ”€â”€ data/                    # Place your datasets here
â”‚   â””â”€â”€ reviews.csv          # Example CSV: text, label
â”œâ”€â”€ src/                     # Core source files
â”‚   â”œâ”€â”€ preprocess.py        # Text cleaning & preprocessing
â”‚   â”œâ”€â”€ dataset.py           # Torch dataset wrapper
â”‚   â”œâ”€â”€ model.py             # DeBERTa classifier with softmax
â”‚   â”œâ”€â”€ train.py             # Training loop
â”‚   â”œâ”€â”€ optimize.py          # MBO hyperparameter tuning
â”‚   â”œâ”€â”€ inference.py         # Prediction with confidence %
â”‚   â””â”€â”€ utils.py             # Helper functions
â”œâ”€â”€ app.py                   # Streamlit demo UI
â”œâ”€â”€ pyproject.toml           # Dependencies (managed by uv)
â”œâ”€â”€ uv.lock                  # Pinned versions
â””â”€â”€ README.md                # You are here ğŸš€
```

---

## ğŸ› ï¸ Setup Instructions

### 1ï¸âƒ£ Clone Repo

```bash
git clone https://github.com/your-username/mbo-deberta-project.git
cd mbo-deberta-project
```

### 2ï¸âƒ£ Sync Dependencies (using uv)

```bash
uv sync
```

### 3ï¸âƒ£ Ensure pip is available inside .venv

```bash
uv venv --with-pip .venv
```

### 4ï¸âƒ£ Install spaCy English model

Required for preprocessing (lemmatization, tokenization).

```bash
uv run python -m spacy download en_core_web_sm
```

### 5ï¸âƒ£ (Optional) Add Dataset

Place your dataset in `data/reviews.csv` with format:

```csv
text,label
"Best pizza! Visit www.promo.com",Advertisement
"I love my new phone, but this place is noisy",Irrelevant
"Never been here but I heard it's bad",RantWithoutVisit
"Amazing food and friendly staff!",Valid
```

---

## â–¶ï¸ Usage

### ğŸ”¹ Train Model

```bash
uv run python -m src.train
```

### ğŸ”¹ Optimize Hyperparameters with MBO

```bash
uv run python -m src.optimize
```

### ğŸ”¹ Run Inference

```bash
uv run python -m src.inference
```

Example:

```python
from src.inference import classify_review
print(classify_review("Best pizza! Visit www.promo.com"))
```

Output:

```json
{
  "Predicted": "Advertisement",
  "Confidence": {
    "Advertisement": 92.5,
    "Irrelevant": 3.1,
    "RantWithoutVisit": 2.0,
    "Valid": 2.4
  }
}
```

### ğŸ”¹ Launch Streamlit Demo

```bash
uv run streamlit run app.py
```

---

## ğŸ“Š Evaluation

â€¢ Metrics: Precision, Recall, F1 per category  
â€¢ Visuals: Confusion Matrix, Confidence Distribution  
â€¢ Explainability: SHAP word highlights for interpretability

---

## ğŸ“š Data Sources

â€¢ Google Maps Restaurant Reviews (Kaggle)  
â€¢ Google Local Reviews (UCSD)  
â€¢ Yelp Review Dataset  
â€¢ Amazon Polarity Reviews

---

## âœ¨ Future Improvements

â€¢ Add multi-lingual support  
â€¢ Deploy API with FastAPI  
â€¢ Extend rule-based filters for more ad/spam patterns  
â€¢ Ensemble with BiLSTM+Word2Vec baseline for robustness

---

## ğŸ‘¨â€ğŸ’» Authors / Team

â€¢ Prabhat & Anvita
